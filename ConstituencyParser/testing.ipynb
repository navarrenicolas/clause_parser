{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509d9d74-2036-4cc5-9734-e9bc4c0eebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import benepar, spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0836a0-4861-4765-bb1d-73447eadfdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/benepar_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_trf')\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3_large\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3_large\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af2cf668-3bf7-491c-a19f-b7fde2512564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_brackets(parsed_string):\n",
    "    # Replace round brackets with square brackets\n",
    "    replaced_string = parsed_string.replace('(', '[').replace(')', ']')\n",
    "    \n",
    "    # Wrap the string with \\begin{forest} and \\end{forest}\n",
    "    final_string = '\\\\begin{forest} ' + replaced_string + ' \\\\end{forest}'\n",
    "    \n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "137acae5-49b6-4494-91ff-8e0456e5b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_info(span):\n",
    "    pred = []\n",
    "    if 'SBAR' in span._.labels:\n",
    "        return []\n",
    "    children = list(span._.children)\n",
    "    if len(children) == 0:\n",
    "        return []\n",
    "    for token in span:\n",
    "        if 'SBAR' in token._.parent._.labels or 'S' in token._.parent._.labels or 'SBAR' in token._.labels or 'S' in token._.labels:\n",
    "            break\n",
    "        pred += [{'str': token.text, 'lemma': token.lemma_, 'POS': token.pos_}]            \n",
    "    return list(filter(lambda x: x['POS'] in ['VERB', 'ADP', 'ADJ', 'AUX'], pred))\n",
    "\n",
    "def get_sentence(span):\n",
    "    parent = span._.parent\n",
    "    if parent == None :\n",
    "        return span\n",
    "    else:\n",
    "        return get_sentence(parent)\n",
    "\n",
    "def get_predicate(span):\n",
    "    #information for each token, from spacy\n",
    "    final_pred = []\n",
    "    token_annots = [{'str': token.text, 'lemma': token.lemma_, 'POS': token.pos_} for token in span]\n",
    "    pos_tags = [token.pos_ for token in span]\n",
    "\n",
    "    #we only want verbs, prepositions, adjectives, and (only if the predicate contains an adjective) auxiliaries\n",
    "    for token in token_annots:\n",
    "        pos = token['POS']\n",
    "        if pos in ['VERB', 'ADP', 'ADJ'] or (\"ADJ\" in pos_tags and pos == \"AUX\"):\n",
    "            final_pred.append(token)\n",
    "    return final_pred\n",
    "    \n",
    "\n",
    "def VP_parent(span):\n",
    "    sbar_idx = span[0].i\n",
    "    parent = span._.parent\n",
    "    if parent == None:\n",
    "        return (False,None)\n",
    "    parent_label = parent._.labels\n",
    "    if \"VP\" in parent_label:\n",
    "        predicate = get_predicate(get_sentence(span)[parent[0].i:sbar_idx+1])\n",
    "        # predicate = get_pred_info(parent)\n",
    "        if len(predicate) == 1:\n",
    "            if predicate[0]['str']=='is':\n",
    "                return (False,None)\n",
    "        return (True,predicate)\n",
    "    elif \"NP\" in parent_label:\n",
    "        return (False,None)\n",
    "    else:\n",
    "        return VP_parent(parent)    \n",
    "\n",
    "def get_SBAR_spans(span):\n",
    "    # if 'SBAR' in span._.labels:\n",
    "    #     return [span]\n",
    "    children = list(span._.children)\n",
    "    spans = []\n",
    "    if len(children)==0:\n",
    "        return spans\n",
    "    for child in children:\n",
    "        if 'SBAR' in child._.labels:\n",
    "            spans += [child]\n",
    "        else:\n",
    "            spans+= get_SBAR_spans(child)\n",
    "    return spans\n",
    "\n",
    "def get_S_parent(span):\n",
    "    parent = span._.parent\n",
    "    if parent == None:\n",
    "        return span\n",
    "    parent_label = parent._.labels\n",
    "    if \"S\" in parent_label:\n",
    "        return parent\n",
    "    else:\n",
    "        return get_S_parent(parent)        \n",
    "\n",
    "def get_SBAR_clause(span):\n",
    "    if 'S' in span._.labels:\n",
    "        return [span]\n",
    "    children = list(span._.children)\n",
    "    clauses = []\n",
    "    if len(children)==0:\n",
    "        return clauses\n",
    "    for child in children:\n",
    "        if 'S' in child._.labels:\n",
    "            clauses += [child]\n",
    "        else:\n",
    "            clauses+= get_SBAR_clause(child)\n",
    "    return clauses\n",
    "\n",
    "def get_clause_type(span):\n",
    "        \"\"\"Returns the type of the embedded clause if there is one in the given sentence.\n",
    "            Identifies clauses as one of 4 clause types\n",
    "                - finite declarative\n",
    "                - finite polar interrogative\n",
    "                - finite constituent interrogative\n",
    "                - finite alternative interrogative\n",
    "            Otherwise the clause will be labeled with \"other\".\n",
    "\n",
    "        :seg: spacy.tokens.span.span\n",
    "            Parsed representation of of text string.\n",
    "        :has_predicate: (bool,spacy.tokens.span.span)\n",
    "        :clause: str\n",
    "            Embedding predicate if it has been previously found.\n",
    "            Carry the last finding in in case predicate has already been found.\n",
    "        :returns: str\n",
    "            Embedded clause type label\n",
    "        \"\"\"\n",
    "        # Convert to string to apply heuristic checks\n",
    "        clause_str = str(span).lower()\n",
    "\n",
    "        first_word = str(list(span._.children)[0]).lower()\n",
    "\n",
    "        # Check for polar and alternative interrogatives\n",
    "        if 'whether' in first_word: \n",
    "            if 'or not' in clause_str:\n",
    "                return 'polar'\n",
    "            if ' or ' in clause_str:\n",
    "                return 'alternative'\n",
    "            else:\n",
    "                return 'polar'\n",
    "\n",
    "        # Check for constituent\n",
    "        if any([word in first_word for word in ['who', 'what', 'when', 'where', 'why', 'how','which']]):\n",
    "               return 'constituent'\n",
    "\n",
    "        return 'declarative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f069656a-d130-4646-b537-fb8725f896a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the string, lemma, and pos tags for the relevant tokens in the predicate\n",
    "def get_pred_info(pred_str):\n",
    "    final_pred = []\n",
    "    if type(pred_str) != str:\n",
    "        pred_str = str(pred_str)\n",
    "    doc = nlp(pred_str)\n",
    "\n",
    "    #information for each token, from spacy\n",
    "    token_annots = [{'str': token.text, 'lemma': token.lemma_, 'POS': token.pos_} for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "\n",
    "    #we only want verbs, prepositions, adjectives, and (only if the predicate contains an adjective) auxiliaries\n",
    "    for token in token_annots:\n",
    "        pos = token['POS']\n",
    "        if pos in ['VERB', 'ADP', 'ADJ'] or (\"ADJ\" in pos_tags and pos == \"AUX\"):\n",
    "            final_pred.append(token)\n",
    "\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f39a03a2-d4b0-498e-a51c-1ee75a92be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_SBAR_flat(span):\n",
    "    SBAR_spans = get_SBAR_spans(span)\n",
    "    clauses = []\n",
    "    for sbar in SBAR_spans:\n",
    "        parent = VP_parent(sbar)\n",
    "        first_word = str(list(sbar._.children)[0]).lower()\n",
    "        if len(get_SBAR_spans(sbar)) > 0:\n",
    "            clauses += parse_SBAR_flat(sbar)    \n",
    "        if not parent[0] or first_word in ['because', 'since', 'while']:\n",
    "            continue\n",
    "        clauses += [{'predicate': parent[1],\n",
    "            'type': get_clause_type(sbar),\n",
    "            'clause' : sbar\n",
    "           }]\n",
    "    return clauses\n",
    "\n",
    "def parse_SBAR_clause(span):\n",
    "    SBAR_spans = self.get_SBAR_spans(span)\n",
    "    clauses = []\n",
    "    \n",
    "    for sbar in SBAR_spans:\n",
    "        parent = self.VP_parent(sbar)\n",
    "        first_word = str(list(sbar._.children)[0]).lower()\n",
    "        if len(self.get_SBAR_spans(sbar)) > 0:\n",
    "            clauses += self.parse_SBAR_clause(sbar)\n",
    "        if not parent[0] or first_word in ['because', 'since', 'while','as']:\n",
    "            continue\n",
    "        clauses += [{'predicate': parent[1],\n",
    "                     'type': self.get_clause_type(sbar),\n",
    "                     'clause' : str(sbar)\n",
    "                     }]\n",
    "        \n",
    "def parse_clauses(span):\n",
    "    return {\"sentence\": span, \n",
    "            \"embedded clauses\": parse_SBAR_flat(span)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a3b5e4f-63d1-4aed-9e7a-174a85f0a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse range (1, 3)\n",
      "Getting predicate in: says how\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': He says how he much enjoyed working for the council,\n",
       " 'embedded clauses': [{'predicate': [{'str': 'says',\n",
       "     'lemma': 'say',\n",
       "     'POS': 'VERB'}],\n",
       "   'type': 'constituent',\n",
       "   'clause': how he much enjoyed working for the council}]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_doc = nlp(\"I think this is something very difficult while Bill thinks it is very simple\")\n",
    "test_doc = nlp(\"He says how he much enjoyed working for the council\")\n",
    "test_span = list(test_doc.sents)[0]\n",
    "parse_clauses(test_span)\n",
    "# print(replace_brackets(list(test_doc.sents)[0]._.parse_string))\n",
    "# [(token._.parent._.labels,token) for token in get_SBAR_spans(test_span)[0]._.parent]\n",
    "# [token for token in ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96aa80-d3ea-4959-af56-0ec7c6c052a0",
   "metadata": {},
   "source": [
    "# Test Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e65e598b-2687-4be6-8f97-239477feafb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': Therefore, those who have not received the overtime pay they are entitled to may want to learn more about whether they are able to recover that compensation through a wage and hour claim.,\n",
       " 'embedded clauses': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = nlp(\"Therefore, those who have not received the overtime pay they are entitled to may want to learn more about whether they are able to recover that compensation through a wage and hour claim.\")\n",
    "test_span = list(test_doc.sents)[0]\n",
    "parse_clauses(test_span)\n",
    "# [(token,token._.labels) for token in test_span]\n",
    "print(replace_brackets(list(test_doc.sents)[0]._.parse_string))\n",
    "# [get_pred_info(VP_parent(s)) for s in get_SBAR_spans(test_span)]\n",
    "# [VP_parent(s) for s in get_SBAR_spans(test_span)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0556a03-34a4-4615-85e1-c8595e62a470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not many people"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = nlp(\"Not many people know whether Mary is telling the truth\")\n",
    "test_span = list(test_doc.sents)[0]\n",
    "# [parse_clauses(sent) for sent in test_doc.sents]\n",
    "# print(replace_brackets(list(test_doc.sents)[0]._.parse_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7fa6865-f030-46cd-a9d9-545fe837ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(), ('SBAR',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x._.labels for x in list(list(test_span._.children)[0]._.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ea831350-2dd5-4f2b-9417-02f710a6a0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicate': [{'str': 'know', 'lemma': 'know', 'POS': 'VERB'}],\n",
       "  'type': 'declarative',\n",
       "  'clause': it is embedded within many other clauses,\n",
       "  'embedded clauses': []}]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.iloc[2]['embedded clauses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "be8cb709-de5d-4a55-9139-b8dbd36119f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " [{'string': decide, 'lemma': 'decide', 'POS': 'VERB', 'parse index': 3},\n",
       "  {'string': in, 'lemma': 'in', 'POS': 'ADP', 'parse index': 4},\n",
       "  {'string': the, 'lemma': 'the', 'POS': 'DET', 'parse index': 5}])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VP_parent(get_SBAR_spans(test_span)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043422c-2812-4161-8f90-b7d19fe3ad09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benepar_env",
   "language": "python",
   "name": "benepar_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
