{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556f0cd6-a3c3-4f2a-a9bc-3ab418eb7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, benepar, nltk\n",
    "#benepar.download('benepar_en3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024abcba-0805-499e-994c-46f181cdbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pyperclip as clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2128c1a4-8a5a-4859-b97c-6f83c62cf4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/benepar_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898ca81e-953e-4daf-b82e-435effc47910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from FullParser.ClauseParser import ClauseParser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5509ab1c-b43e-40d0-a5b3-78515a7f8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ClauseParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7d4baf-81de-4c35-81cb-1d699cf7cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77a29a-1322-481d-ab02-9d1f4ca9d4e1",
   "metadata": {},
   "source": [
    "# Parser testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6f109320-e4c1-431b-bf46-14cb5137e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_sent(sent):\n",
    "    return list(nlp(sent).sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c56743e7-c668-428a-a924-04c1a1894b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_parse(sent):\n",
    "    return nltk.Tree.fromstring(list(nlp(sent).sents)[0]._.parse_string).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "281c4464-cdd8-4fcc-a670-c3bf06ba94da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     S                                                                                      \n",
      "  ___|______                                                                                 \n",
      " |          VP                                                                              \n",
      " |    ______|______________                                                                  \n",
      " |   |      |              VP                                                               \n",
      " |   |      |      ________|__________                                                       \n",
      " |   |      |     |                  SBAR                                                   \n",
      " |   |      |     |         __________|__________                                            \n",
      " |   |      |     |        |                     S                                          \n",
      " |   |      |     |        |                 ____|__________                                 \n",
      " |   |      |     |        |                |               VP                              \n",
      " |   |      |     |        |                |     __________|_____                           \n",
      " |   |      |     |        |                |    |                PP                        \n",
      " |   |      |     |        |                |    |     ___________|____                      \n",
      " |   |      |     |        |                |    |    |               SBAR                  \n",
      " |   |      |     |        |                |    |    |      __________|_____                \n",
      " |   |      |     |        |                |    |    |     |                S              \n",
      " |   |      |     |        |                |    |    |     |      __________|____           \n",
      " |   |      |     |        |                |    |    |     |     |               VP        \n",
      " |   |      |     |        |                |    |    |     |     |           ____|_____     \n",
      " NP  |     ADVP   |      WHADJP             NP   |    |   WHADVP  NP         |          VP  \n",
      " |   |      |     |    ____|__________      |    |    |     |     |          |          |    \n",
      "PRP  MD     RB    VB WRB   JJ    CC   JJ   PRP  VBP   IN   WRB   PRP         MD         VB  \n",
      " |   |      |     |   |    |     |    |     |    |    |     |     |          |          |    \n",
      "You will totally see how  real  and honest they are about  how   they      could     forgive\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'You will totally see how real and honest they are about how they could forgive',\n",
       "  'predicate': [{'str': 'about', 'lemma': 'about', 'POS': 'ADP'}],\n",
       "  'type': 'constituent',\n",
       "  'clause': 'how they could forgive'},\n",
       " {'sentence': 'You will totally see how real and honest they are about how they could forgive',\n",
       "  'predicate': [{'str': 'see', 'lemma': 'see', 'POS': 'VERB'}],\n",
       "  'type': 'constituent',\n",
       "  'clause': 'how real and honest they are about how they could forgive'}]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_sent = \"Bill told his friends about how he managed to climb everest\"\n",
    "# test_sent =\"It was understood by most that we are here for fun\"\n",
    "# test_sent =\"We need to think about what is needed to help us do both these things at the same time.\"\n",
    "# test_sent = \"I'm very aware of when I'm doing it nowadays\"\n",
    "# test_sent = \"We are still unclear as to whether or not Canada is a state\"\n",
    "# test_sent = \"Bob knows that mary won the race and that Bill lost the race\"\n",
    "# test_sent = \"Bob said to the person he loves that mary won the race and that Bill lost the race\"\n",
    "test_sent = \"You will totally see how real and honest they are about how they could forgive\"\n",
    "# test_sent = \"Even his friends aren't sure whether he should come back, leading to a frank discussion of resurrection\"\n",
    "x = nlp_sent(test_sent)\n",
    "nlp_parse(test_sent)\n",
    "parser.parse_clauses(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e1363699-a68f-45d6-83c4-81f5c135ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "    \n",
    "def get_last_predicate_tokens(span,sbar):\n",
    "    if span == sbar:\n",
    "        return []\n",
    "    tokens = []\n",
    "    for token in span:\n",
    "        if 'SBAR' in token._.parent._.labels:\n",
    "            return tokens\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "def check_PP_has_SBAR(PP_span,sbar):\n",
    "    has_SBAR = False\n",
    "    children = PP_span._.children\n",
    "    for child in PP_span._.children:\n",
    "        if 'PP' in child._.labels:\n",
    "            has_SBAR = check_PP_has_SBAR(child,sbar) \n",
    "        if child == sbar:\n",
    "            has_SBAR = True\n",
    "            break\n",
    "    return has_SBAR\n",
    "        \n",
    "def check_SBAR_match(token,sbar):\n",
    "    parent = token._.parent\n",
    "    if 'NP' in parent._.labels:\n",
    "        return False\n",
    "    if 'PP' in parent._.labels:\n",
    "        return check_PP_has_SBAR(parent,sbar)\n",
    "    if 'SBAR' in parent._.labels:\n",
    "        return False\n",
    "    return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d5155de6-ac9a-4a83-9fc8-00b323eb6798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how real and honest they are about how they could forgive\n",
      "see how\n",
      "see how real and honest they are about how they could forgive\n"
     ]
    }
   ],
   "source": [
    "sbar_span = parser.get_SBAR_spans(x)[0]\n",
    "pred_string = parser.test_pred_string(sbar_span)\n",
    "VP_parent = parser.VP_parent_simple(sbar_span)\n",
    "\n",
    "print(sbar_span)\n",
    "print(pred_string)\n",
    "print(VP_parent)\n",
    "# parser.get_predicate(flatten([[t for t in child]for child in list(VP_parent._.children)[:-1] if not any([bad_label in child._.labels for bad_label in ['S','SBAR', 'NP', 'PP']])])+get_last_predicate_tokens(list(VP_parent._.children)[-1],sbar_span),sbar_span)\n",
    "# [c._.labels for c in list(VP_parent._.children)]\n",
    "# [(t,t._.parent._.labels,[ (child, str(child) in str(sbar_span) ) for child in (t._.parent._.children)]) for t in parser.test_pred_string(sbar_span)]\n",
    "# [t for t in parser.test_pred_string(sbar_span) if not any([bad_label in t._.parent._.labels for bad_label in ['SBAR', 'NP']])]\n",
    "# [[child for child in t._.parent._.children] for t in pred_string]\n",
    "# [child for child in pred_string[-1]._.parent._.children]\n",
    "# [(t,t._.parent._.labels, [child._.labels for child in t._.parent._.children]) for t in pred_string]\n",
    "# [(t,t._.parent._.labels, t._.parent ) for t in pred_string]\n",
    "# parser.get_predicate([t for t in pred_string if check_SBAR_match(t,sbar_span)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b75a659-0ba0-4f2c-b79c-a715f30d4b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how they could forgive\n",
      "are about how\n",
      "are about how they could forgive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[are, about]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbar_span = parser.get_SBAR_spans(parser.get_SBAR_spans(x)[0])[0]\n",
    "pred_string = parser.test_pred_string(sbar_span)\n",
    "VP_parent = parser.VP_parent_simple(sbar_span)\n",
    "\n",
    "print(sbar_span)\n",
    "print(pred_string)\n",
    "print(VP_parent)\n",
    "[(child,child._.labels) for child in VP_parent._.children]\n",
    "flatten([[t for t in child]for child in list(VP_parent._.children)[:-1] if not any([bad_label in child._.labels for bad_label in ['S','SBAR', 'NP', 'PP']])])+get_last_predicate_tokens(list(VP_parent._.children)[-1],sbar_span) \n",
    "\n",
    "# [(t,t._.parent._.labels,[ (child, str(child) in str(sbar_span) ) for child in (t._.parent._.children)]) for t in parser.test_pred_string(sbar_span)]\n",
    "# [t for t in parser.test_pred_string(sbar_span) if not any([bad_label in t._.parent._.labels for bad_label in ['SBAR', 'NP']])]\n",
    "# [[child for child in t._.parent._.children] for t in pred_string]\n",
    "# [child for child in pred_string[-1]._.parent._.children]\n",
    "# [(t,t._.parent._.labels, [child._.labels for child in t._.parent._.children]) for t in pred_string]\n",
    "# [(t,t._.parent._.labels, list(t._.parent._.children)) for t in pred_string]\n",
    "# parser.get_predicate([t for t in pred_string if check_SBAR_match(t,sbar_span)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16cf90-91a2-41da-887c-1d0ba9acfa6f",
   "metadata": {},
   "source": [
    "# Large Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7d829ac8-da82-4443-b9de-45c9d35a843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully processed sample of sample\n",
    "# ECs = pd.concat([pd.read_json(f'./sample_parses/v1_5r2_sample-{str(i).zfill(4)}.txt.json') for i in range(103)])\n",
    "new_ECs = pd.read_json('./v1_5r2_sample-0005.txt.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1615a-93cf-4b0d-9003-ad15fdf8cb49",
   "metadata": {},
   "source": [
    "## Predicate Lemma distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "68011cd8-71fe-4d16-9b73-458d2191301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick and dirty concatenation of predicate lemmas\n",
    "# ECs['pred_lemmas'] = ECs['predicate'].apply(lambda x: ' '.join([pred['lemma'] for pred in x]))\n",
    "new_ECs['pred_lemmas'] = new_ECs['predicate'].apply(lambda x: ' '.join([pred['lemma'] for pred in x]))\n",
    "ECs_filtered = new_ECs[new_ECs['pred_lemmas'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e263eff8-e140-4532-985e-7cad0156a608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_lemmas\n",
       "think                                 1822\n",
       "say                                   1625\n",
       "know                                  1049\n",
       "hope                                   913\n",
       "make sure                              429\n",
       "                                      ... \n",
       "’re happy with                           1\n",
       "’re hopeful                              1\n",
       "’re prepared                             1\n",
       "’re sweet                                1\n",
       "’s getting find by local potential       1\n",
       "Name: count, Length: 4484, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ECs_filtered.groupby('type').pred_lemmas.value_counts()['declarative']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8bf4d-623f-4391-b072-1093417ccaba",
   "metadata": {},
   "source": [
    "## MegaAcceptability comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "15e51b1b-b295-4f9d-b592-b3e3c462817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mega acceptability White & Rawlins 2016, 2020 An & White 2020\n",
    "mega_v1 = pd.read_csv('/Users/s2518809/Downloads/mega-acceptability-v1/mega-acceptability-v1-normalized.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63a52133-e2a9-4b91-b562-52ba1d3aa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_v1_finite = mega_v1[mega_v1.frame.isin(['NP Ved that S', 'NP Ved S','NP was Ved that S', 'NP was Ved S',\n",
    "                                                               'NP Ved whether S', 'NP Ved whichNP S',\n",
    "                                                               'NP was Ved whether S', 'NP was Ved whichNP S'])]\n",
    "\n",
    "mega_v1_finite_declarative_frames = mega_v1[mega_v1.frame.isin(['NP Ved that S', 'NP Ved S'])]\n",
    "\n",
    "mega_v1_finite_constituent_frames = mega_v1[mega_v1.frame.isin(['NP Ved whichNP S'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8b4b65e0-b13c-41c3-a040-9b5b733e09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_acceptabilities = mega_v1_finite.groupby('verb')['responsenorm'].max()\n",
    "declarative_acceptabilities = mega_v1_finite_declarative_frames.groupby('verb')['responsenorm'].max()\n",
    "constituent_acceptabilities = mega_v1_finite_constituent_frames.groupby('verb')['responsenorm'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2cbc178e-3e93-4e41-9483-9d9941c836df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_verbs = set(mega_v1.verb.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559f92c-d1da-4b71-85c1-b70b4418d232",
   "metadata": {},
   "source": [
    "Predicates found from MegaAcceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b575de3c-773e-403b-a9ef-ffbbcf571687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_MA_preds = {pred for pred in set(new_ECs['pred_lemmas'].values) if pred in mega_verbs}\n",
    "len(found_MA_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a44bd35c-144b-4da6-99d3-e0d3d0a3cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "declarative_ECs = new_ECs[new_ECs['type']=='declarative']\n",
    "constituent_ECs = new_ECs[new_ECs['type']=='constituent']\n",
    "found_MA_preds_declarative = {pred for pred in set(declarative_ECs['pred_lemmas'].values) if pred in mega_verbs}\n",
    "found_MA_preds_constituent = {pred for pred in set(constituent_ECs['pred_lemmas'].values) if pred in mega_verbs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f318047-0dc4-4ccd-a77e-3f1a0ebc5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_pred_counts = new_ECs[new_ECs['pred_lemmas'].apply(lambda x: x in found_MA_preds)]['pred_lemmas'].value_counts()\n",
    "MA_pred_counts_declarative = declarative_ECs[declarative_ECs['pred_lemmas'].apply(lambda x: x in found_MA_preds)]['pred_lemmas'].value_counts()\n",
    "MA_pred_counts_constituent = constituent_ECs[constituent_ECs['pred_lemmas'].apply(lambda x: x in found_MA_preds)]['pred_lemmas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c371e1d8-bd39-4906-b93d-41240e86d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_pred_counts_full = pd.concat([pd.Series(0,index=mega_verbs.difference(set(MA_pred_counts.index))), MA_pred_counts])\n",
    "MA_pred_counts_declarative_full = pd.concat([pd.Series(0,index=mega_verbs.difference(set(MA_pred_counts_declarative.index))), MA_pred_counts_declarative])\n",
    "MA_pred_counts_constituent_full = pd.concat([pd.Series(0,index=mega_verbs.difference(set(MA_pred_counts_constituent.index))), MA_pred_counts_constituent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d69dc4-1c74-4ad2-9b2c-9292450de95d",
   "metadata": {},
   "source": [
    "### Correlation of frequency data with acceptability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7ef51cf1-19d5-4cc3-b027-d4626b226b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite clauses correlation 0.1550118041970863\n",
      "Declarative clauses correlation 0.17143578555339367\n",
      "Constituent clauses correlation 0.11164616665752561\n"
     ]
    }
   ],
   "source": [
    "print('Finite clauses correlation',mega_acceptabilities.corr(MA_pred_counts_full))\n",
    "print('Declarative clauses correlation',declarative_acceptabilities.corr(MA_pred_counts_declarative_full))\n",
    "print('Constituent clauses correlation',constituent_acceptabilities.corr(MA_pred_counts_constituent_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e48a8-f776-474d-80a8-d5b4780fa478",
   "metadata": {},
   "source": [
    "## Analyzing Predicates beyond MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "683ba54a-f7a3-484e-9064-13c4978ae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicates not in MegaAcceptability\n",
    "extra_MA_preds = set(filter( lambda x: all(c.isalnum() for c in x), {pred for pred in set(new_ECs[new_ECs['predicate'].apply(lambda x: len(x)==1)]['pred_lemmas'].values) if pred not in mega_verbs}))\n",
    "# Non-alphanimeric predicates\n",
    "extra_MA_preds_nonan = set(filter( lambda x: any( not c.isalnum() for c in x), {pred for pred in set(new_ECs[new_ECs['predicate'].apply(lambda x: len(x)==1)]['pred_lemmas'].values) if pred not in mega_verbs}))\n",
    "# complex predicates\n",
    "complex_preds = set(new_ECs[new_ECs['predicate'].apply(lambda x: len(x)>1)]['pred_lemmas'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "79a0d6ac-acb2-4af6-96c2-828dd65b4762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'realize' in mega_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5cc3bb6c-fbc7-4813-8cf1-389132ff8bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_lemmas\n",
       "hide        12\n",
       "visit       12\n",
       "drop        12\n",
       "break       12\n",
       "win         11\n",
       "join        11\n",
       "achieve     11\n",
       "enter       11\n",
       "remove      11\n",
       "complete    10\n",
       "support     10\n",
       "arrive      10\n",
       "glad        10\n",
       "improve     10\n",
       "drink       10\n",
       "live         9\n",
       "exist        9\n",
       "as           9\n",
       "thought      9\n",
       "arise        9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_MA_pred_counts = new_ECs[new_ECs['pred_lemmas'].apply(lambda x: x in extra_MA_preds)]['pred_lemmas'].value_counts() \n",
    "extra_MA_pred_counts[50:70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef82c42-7122-4ccf-83b9-d8d6fd559775",
   "metadata": {},
   "source": [
    "### Extraneous predicates from MA\n",
    "\n",
    "Here we can look at the specific parses of the common predicates found outside of the the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6201bccf-6e78-4f75-9a64-913ee3fa315c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weird predicate: glad\n",
      "                                      S                                       \n",
      "   ___________________________________|_____________________________________   \n",
      "  |             |                 |   |            S                        | \n",
      "  |             |                 |   |            |                        |  \n",
      "  |             |                 |   |            VP                       | \n",
      "  |             |                 |   |    ________|___                     |  \n",
      "  |             |                 |   |   |           ADJP                  | \n",
      "  |             |                 |   |   |    ________|______              |  \n",
      "  |             |                 |   |   |   |              SBAR           | \n",
      "  |             |                 |   |   |   |               |             |  \n",
      "  |             |                 |   |   |   |               S             | \n",
      "  |             |                 |   |   |   |     __________|_____        |  \n",
      "  |             PP                |   |   |   |    |                VP      | \n",
      "  |      _______|____             |   |   |   |    |           _____|___    |  \n",
      "  NP    |            NP           NP  |   |   |    NP         |         NP  | \n",
      "  |     |    ________|______      |   |   |   |    |          |         |   |  \n",
      " NNS    IN  DT       JJ     NN   NNP  :  VBP  JJ  PRP        VBD       PRP  . \n",
      "  |     |   |        |      |     |   |   |   |    |          |         |   |  \n",
      "Thanks for the     great comment Ann  ,  I'm glad you      enjoyed      it  . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/benepar_env/lib/python3.12/site-packages/torch/distributions/distribution.py:53: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set the predicate we want to look at\n",
    "weird_predicate = extra_MA_pred_counts.index[62]\n",
    "print(f'Weird predicate: {weird_predicate}')\n",
    "# Get a sentence from that weird predicate\n",
    "weird_pred_sent = new_ECs[new_ECs['pred_lemmas'] == weird_predicate ].iloc[0]['sentence']\n",
    "# Print syntactic tree\n",
    "nlp_parse(weird_pred_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "7b2dfc5a-c915-4d5d-868e-44d20b045ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence       Christ is in you?--unless, indeed, you fail to...\n",
       "predicate           [{'str': 'in', 'lemma': 'in', 'POS': 'ADP'}]\n",
       "type                                                 declarative\n",
       "clause           you?--unless, indeed, you fail to meet the test\n",
       "pred_lemmas                                                   in\n",
       "Name: 5806, dtype: object"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parser.parse_clauses(list(nlp(weird_pred_sent).sents)[0]) # Full Parse\n",
    "new_ECs[new_ECs['pred_lemmas'] == weird_predicate ].iloc[15] # Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "b6db3018-caee-478e-870e-8775a6e25fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': \"What safeguards are in place that you eill respect the Penan's rights\",\n",
       "  'predicate': [{'str': 'in', 'lemma': 'in', 'POS': 'ADP'}],\n",
       "  'type': 'declarative',\n",
       "  'clause': \"that you eill respect the Penan's rights\"}]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = \"What safeguards are in place that you eill respect the Penan's rights\"\n",
    "# nlp_parse(test_sent)\n",
    "# parser.parse_clauses(list(nlp(test_sent).sents)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8d06ed0f-25b7-4dfa-a5ad-324e7751bda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "clip.copy(weird_pred_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f29b60-a03b-40f5-a196-47be1b3983a7",
   "metadata": {},
   "source": [
    "## Empty Predicate Parses\n",
    "Lets look at the empty predicates in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "52d1a818-947f-416d-aed4-23ffc4fb4e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37293, 5)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ECs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "738cea97-356c-4534-8a95-804022dc6b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence       And then; \"That is how we are different, Axinos.\n",
      "predicate                                                    []\n",
      "type                                                constituent\n",
      "clause                             how we are different, Axinos\n",
      "pred_lemmas                                                    \n",
      "Name: 53, dtype: object\n",
      "                           FRAG                                   \n",
      "  __________________________|___________________________________   \n",
      " |   |    |   |        S                                        | \n",
      " |   |    |   |    ____|____                                    |  \n",
      " |   |    |   |   |         VP                                  | \n",
      " |   |    |   |   |     ____|_____                              |  \n",
      " |   |    |   |   |    |         SBAR                           | \n",
      " |   |    |   |   |    |     _____|____                         |  \n",
      " |   |    |   |   |    |    |          S                        | \n",
      " |   |    |   |   |    |    |      ____|______                  |  \n",
      " |   |    |   |   |    |    |     |           VP                | \n",
      " |   |    |   |   |    |    |     |     ______|___________      |  \n",
      " |  ADVP  |   |   NP   |  WHADVP  NP   |     ADJP    |    NP    | \n",
      " |   |    |   |   |    |    |     |    |      |      |    |     |  \n",
      " CC  RB   :   ``  DT  VBZ  WRB   PRP  VBP     JJ     ,   NNPS   . \n",
      " |   |    |   |   |    |    |     |    |      |      |    |     |  \n",
      "And then  ;   \"  That  is  how    we  are different  ,  Axinos  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Declarative empty predicates\n",
    "test = new_ECs[(new_ECs['pred_lemmas'] == '') & (new_ECs['type']== 'constituent')].iloc[2]\n",
    "print(test)\n",
    "tree = nltk.Tree.fromstring(list(nlp(test['sentence']).sents)[0]._.parse_string)\n",
    "# Print the tree in ASCII\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "5a32c7ef-8f33-4c03-874c-c85ea57cda67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   S                                \n",
      "  _________________|______________________________   \n",
      " |        VP                                      | \n",
      " |    ____|___                                    |  \n",
      " |   |       SBAR                                 | \n",
      " |   |        |                                   |  \n",
      " |   |        S                                   | \n",
      " |   |     ___|_________                          |  \n",
      " |   |    |             VP                        | \n",
      " |   |    |    _________|______________           |  \n",
      " NP  |    NP  |    |    |    |         NP         | \n",
      " |   |    |   |    |    |    |     ____|____      |  \n",
      "PRP VBP  PRP VBZ   RB   JJ   IN   DT       NNS    . \n",
      " |   |    |   |    |    |    |    |         |     |  \n",
      " I  know she  ’s   so right  on these     points  . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/benepar_env/lib/python3.12/site-packages/torch/distributions/distribution.py:53: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Declarative empty predicates\n",
    "test = new_ECs[(new_ECs['pred_lemmas'] == '') & (new_ECs['type']== 'declarative')][['sentence','clause']].iloc[1]['sentence']\n",
    "tree = nltk.Tree.fromstring(list(nlp(test).sents)[0]._.parse_string)\n",
    "# Print the tree in ASCII\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c38cca4-b00d-4171-b778-185bb811931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the top N elements of a list\n",
    "def top_n(a,n):\n",
    "    return np.flip(np.argsort(a)[-n:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76cae8f-5536-4941-893f-2d42b1bcbd17",
   "metadata": {},
   "source": [
    "# Interrogative clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "22b4469e-cd39-416e-a633-0e1c7af7f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "whether_ECs = pd.concat([pd.read_json(f'./whether_clauses/v1_5r2_sample_whether-{str(i).zfill(4)}.txt.json') for i in range(102)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "ae6bf00e-34d2-4677-98de-5f949d573cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5793, 5)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whether_ECs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "5d4eaa18-137e-4f0b-9a94-18ee0d621534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick and dirty concatenation of predicate lemmas\n",
    "whether_ECs['pred_lemmas'] = whether_ECs['predicate'].apply(lambda x: ' '.join([pred['lemma'] for pred in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "daf34d3b-b587-448a-974f-19810566d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_lemmas\n",
       "care                      164\n",
       "distinguish               102\n",
       "go                        102\n",
       "rely on of                 99\n",
       "assess                     96\n",
       "for                        96\n",
       "leave                      92\n",
       "choose                     88\n",
       "forget                     87\n",
       "matter                     82\n",
       "actual                     68\n",
       "on                         66\n",
       "check                      64\n",
       "be different in depend     60\n",
       "decide                     43\n",
       "adjust                     36\n",
       "be unaware                  7\n",
       "know                        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whether_ECs.groupby('type')['pred_lemmas'].value_counts()['alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "e49f270e-07cc-40bb-b517-fad1a81a9cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_lemmas\n",
       "care                      164\n",
       "distinguish               102\n",
       "go                        102\n",
       "rely on of                 99\n",
       "assess                     96\n",
       "for                        96\n",
       "leave                      92\n",
       "choose                     88\n",
       "forget                     87\n",
       "matter                     82\n",
       "actual                     68\n",
       "on                         66\n",
       "check                      64\n",
       "be different in depend     60\n",
       "decide                     43\n",
       "adjust                     36\n",
       "be unaware                  7\n",
       "know                        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whether_ECs.groupby('type')['pred_lemmas'].value_counts()['alternative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "ef2bfa92-417f-4dc8-821b-c8ff7a8e1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence       Dr Leon’s primary job scope is to welcome newc...\n",
      "predicate      [{'str': 'welcome', 'lemma': 'welcome', 'POS':...\n",
      "type                                                       polar\n",
      "clause                               whether they like it or not\n",
      "pred_lemmas                                              welcome\n",
      "Name: 64, dtype: object\n",
      "                                                          S                                                        \n",
      "           _______________________________________________|______________________________________________________   \n",
      "          |                                                            VP                                        | \n",
      "          |                      ______________________________________|_____                                    |  \n",
      "          |                     |                                            S                                   | \n",
      "          |                     |                                            |                                   |  \n",
      "          |                     |                                            VP                                  | \n",
      "          |                     |                                       _____|_______________________________    |  \n",
      "          |                     |                                      S                                     |   | \n",
      "          |                     |                                      |                                     |   |  \n",
      "          |                     |                                      VP                                    |   | \n",
      "          |                     |    __________________________________|_____                                |   |  \n",
      "          |                     |   |                                        VP                              |   | \n",
      "          |                     |   |      __________________________________|_____                          |   |  \n",
      "          |                     |   |     |               |            |          SBAR                       |   | \n",
      "          |                     |   |     |               |            |      _____|____                     |   |  \n",
      "          |                     |   |     |               |            |     |          S                    |   | \n",
      "          |                     |   |     |               |            |     |      ____|________            |   |  \n",
      "          |                     |   |     |               |            |     |     |             VP          |   | \n",
      "          |                     |   |     |               |            |     |     |          ___|_______    |   |  \n",
      "          NP                    |   |     |               |            |     |     |         VP      |   |   |   | \n",
      "      ____|________________     |   |     |               |            |     |     |     ____|___    |   |   |   |  \n",
      "     NP         |     |    |    |   |     |               NP           |     |     NP   |        NP  |   |   |   | \n",
      "  ___|____      |     |    |    |   |     |         ______|_____       |     |     |    |        |   |   |   |   |  \n",
      "NNP NNP  POS    JJ    NN   NN  VBZ  TO    VB      NNS     CC   NNS     ``    IN   PRP  VBP      PRP  CC  RB  ''  . \n",
      " |   |    |     |     |    |    |   |     |        |      |     |      |     |     |    |        |   |   |   |   |  \n",
      " Dr Leon  ’s primary job scope  is  to welcome newcomers and visitors  “  whether they like      it  or not  ”   . \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/benepar_env/lib/python3.12/site-packages/torch/distributions/distribution.py:53: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Declarative empty predicates\n",
    "test = whether_ECs[(whether_ECs['pred_lemmas'] == 'welcome') & (whether_ECs['type']== 'polar')].iloc[0]\n",
    "print(test)\n",
    "tree = nltk.Tree.fromstring(list(nlp(test['sentence']).sents)[0]._.parse_string)\n",
    "# Print the tree in ASCII\n",
    "tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f1f44-0c52-4469-bb86-98d577b8c3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benepar_env",
   "language": "python",
   "name": "benepar_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
